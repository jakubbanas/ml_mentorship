{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f948111b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jupyter_black\n",
    "\n",
    "jupyter_black.load(line_length=120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b9d9fd84",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# import nltk\n",
    "# nltk.download(\"stopwords\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbcfb122",
   "metadata": {},
   "source": [
    "# Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0dab91fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words(\"english\"))\n",
    "\n",
    "\n",
    "def count_stop_words(text):\n",
    "    words = text.split()\n",
    "    stop_words_count = sum(1 for word in words if word in stop_words)\n",
    "    return stop_words_count\n",
    "\n",
    "\n",
    "def clean_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"http\\S+|www\\S+|https\\S+\", \"<url>\", text, flags=re.MULTILINE)  # Remove URLs\n",
    "    text = re.sub(r\"\\@\\w+\", \"<mention>\", text)  # Remove mentions\n",
    "    text = re.sub(r\"|\\#\", \"\", text)  # Remove hashtags\n",
    "    text = re.sub(r\"[^\\w\\s]\", \"\", text)  # Remove punctuation\n",
    "    text_tokens = text.split()\n",
    "    filtered_words = [w for w in text_tokens if not w in stop_words]\n",
    "    return \" \".join(filtered_words)\n",
    "\n",
    "\n",
    "def has_url(text):\n",
    "    return 1 if re.search(r\"http\\S+|www\\S+|https\\S+\", text) else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e44130b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"datasets/train.csv\")\n",
    "\n",
    "df[\"text_length\"] = df[\"text\"].astype(str).apply(len)\n",
    "df[\"word_count\"] = df[\"text\"].astype(str).apply(lambda x: len(x.split()))\n",
    "df[\"stop_words_count\"] = df[\"text\"].apply(count_stop_words)\n",
    "df[\"has_url\"] = df[\"text\"].apply(has_url)\n",
    "df[\"clean_text\"] = df[\"text\"].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2ca6d898",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>target</th>\n",
       "      <th>text_length</th>\n",
       "      <th>word_count</th>\n",
       "      <th>stop_words_count</th>\n",
       "      <th>has_url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>7613.000000</td>\n",
       "      <td>7613.00000</td>\n",
       "      <td>7613.000000</td>\n",
       "      <td>7613.000000</td>\n",
       "      <td>7613.000000</td>\n",
       "      <td>7613.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>5441.934848</td>\n",
       "      <td>0.42966</td>\n",
       "      <td>101.037436</td>\n",
       "      <td>14.903586</td>\n",
       "      <td>3.761198</td>\n",
       "      <td>0.522265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3137.116090</td>\n",
       "      <td>0.49506</td>\n",
       "      <td>33.781325</td>\n",
       "      <td>5.732604</td>\n",
       "      <td>3.208630</td>\n",
       "      <td>0.499537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2734.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>78.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>5408.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>107.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>8146.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>133.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>10873.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>157.000000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id      target  text_length   word_count  stop_words_count  \\\n",
       "count   7613.000000  7613.00000  7613.000000  7613.000000       7613.000000   \n",
       "mean    5441.934848     0.42966   101.037436    14.903586          3.761198   \n",
       "std     3137.116090     0.49506    33.781325     5.732604          3.208630   \n",
       "min        1.000000     0.00000     7.000000     1.000000          0.000000   \n",
       "25%     2734.000000     0.00000    78.000000    11.000000          1.000000   \n",
       "50%     5408.000000     0.00000   107.000000    15.000000          3.000000   \n",
       "75%     8146.000000     1.00000   133.000000    19.000000          6.000000   \n",
       "max    10873.000000     1.00000   157.000000    31.000000         18.000000   \n",
       "\n",
       "           has_url  \n",
       "count  7613.000000  \n",
       "mean      0.522265  \n",
       "std       0.499537  \n",
       "min       0.000000  \n",
       "25%       0.000000  \n",
       "50%       1.000000  \n",
       "75%       1.000000  \n",
       "max       1.000000  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9152aa6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>text_length</th>\n",
       "      <th>word_count</th>\n",
       "      <th>stop_words_count</th>\n",
       "      <th>has_url</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "      <td>69</td>\n",
       "      <td>13</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>deeds reason earthquake may allah forgive us</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "      <td>38</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>forest fire near la ronge sask canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "      <td>133</td>\n",
       "      <td>22</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>residents asked shelter place notified officer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "      <td>65</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>13000 people receive wildfires evacuation orde...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>1</td>\n",
       "      <td>88</td>\n",
       "      <td>16</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>got sent photo ruby alaska smoke wildfires pou...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location                                               text  \\\n",
       "0   1     NaN      NaN  Our Deeds are the Reason of this #earthquake M...   \n",
       "1   4     NaN      NaN             Forest fire near La Ronge Sask. Canada   \n",
       "2   5     NaN      NaN  All residents asked to 'shelter in place' are ...   \n",
       "3   6     NaN      NaN  13,000 people receive #wildfires evacuation or...   \n",
       "4   7     NaN      NaN  Just got sent this photo from Ruby #Alaska as ...   \n",
       "\n",
       "   target  text_length  word_count  stop_words_count  has_url  \\\n",
       "0       1           69          13                 5        0   \n",
       "1       1           38           7                 0        0   \n",
       "2       1          133          22                 9        0   \n",
       "3       1           65           8                 1        0   \n",
       "4       1           88          16                 6        0   \n",
       "\n",
       "                                          clean_text  \n",
       "0       deeds reason earthquake may allah forgive us  \n",
       "1              forest fire near la ronge sask canada  \n",
       "2  residents asked shelter place notified officer...  \n",
       "3  13000 people receive wildfires evacuation orde...  \n",
       "4  got sent photo ruby alaska smoke wildfires pou...  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bd22ff8",
   "metadata": {},
   "source": [
    "# Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "84696222",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_test = train_test_split(\n",
    "    df,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    shuffle=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f73d707",
   "metadata": {},
   "source": [
    "## count vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4a6aedaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vectorizer = CountVectorizer(\n",
    "    lowercase=True,\n",
    "    stop_words=\"english\",\n",
    "    max_features=1000,\n",
    "    ngram_range=(1, 2),\n",
    ")\n",
    "X_train = count_vectorizer.fit_transform(df_train[\"clean_text\"])\n",
    "X_test = count_vectorizer.transform(df_test[\"clean_text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff06594a",
   "metadata": {},
   "source": [
    "## TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "28d9d10b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer(\n",
    "    lowercase=True,\n",
    "    stop_words=\"english\",\n",
    "    max_features=1000,\n",
    "    ngram_range=(1, 2),\n",
    ")\n",
    "X_train_tfidf = tfidf_vectorizer.fit_transform(df_train[\"clean_text\"])\n",
    "X_test_tfidf = tfidf_vectorizer.transform(df_test[\"clean_text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91d37d8a",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f63d2b64",
   "metadata": {},
   "source": [
    "## SVC - CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b7568e91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.86      0.82       874\n",
      "           1       0.79      0.68      0.73       649\n",
      "\n",
      "    accuracy                           0.79      1523\n",
      "   macro avg       0.79      0.77      0.78      1523\n",
      "weighted avg       0.79      0.79      0.78      1523\n",
      "\n",
      "Accuracy: 0.7872619829284307\n"
     ]
    }
   ],
   "source": [
    "svm = SVC(kernel=\"linear\", C=1.0, random_state=42)\n",
    "svm.fit(X_train, df_train[\"target\"])\n",
    "y_pred = svm.predict(X_test)\n",
    "\n",
    "print(classification_report(df_test[\"target\"], y_pred))\n",
    "print(\"Accuracy:\", accuracy_score(df_test[\"target\"], y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddbc196a",
   "metadata": {},
   "source": [
    "## XGBoost - CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "422916c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.90      0.82       874\n",
      "           1       0.82      0.61      0.70       649\n",
      "\n",
      "    accuracy                           0.78      1523\n",
      "   macro avg       0.79      0.75      0.76      1523\n",
      "weighted avg       0.78      0.78      0.77      1523\n",
      "\n",
      "Accuracy: 0.7760998030203545\n"
     ]
    }
   ],
   "source": [
    "bst = XGBClassifier()\n",
    "bst.fit(X_train, df_train[\"target\"])\n",
    "preds = bst.predict(X_test)\n",
    "\n",
    "print(classification_report(df_test[\"target\"], preds))\n",
    "print(\"Accuracy:\", accuracy_score(df_test[\"target\"], preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "359f7d27",
   "metadata": {},
   "source": [
    "## SVC - TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "86ae308c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.86      0.82       874\n",
      "           1       0.78      0.68      0.73       649\n",
      "\n",
      "    accuracy                           0.78      1523\n",
      "   macro avg       0.78      0.77      0.77      1523\n",
      "weighted avg       0.78      0.78      0.78      1523\n",
      "\n",
      "Accuracy: 0.7820091923834537\n"
     ]
    }
   ],
   "source": [
    "svm = SVC(kernel=\"linear\", C=1.0, random_state=42)\n",
    "svm.fit(X_train_tfidf, df_train[\"target\"])\n",
    "y_pred = svm.predict(X_test_tfidf)\n",
    "\n",
    "print(classification_report(df_test[\"target\"], y_pred))\n",
    "print(\"Accuracy:\", accuracy_score(df_test[\"target\"], y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d968b94",
   "metadata": {},
   "source": [
    "## XGBoost - TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9c6e77ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.88      0.82       874\n",
      "           1       0.80      0.63      0.70       649\n",
      "\n",
      "    accuracy                           0.77      1523\n",
      "   macro avg       0.78      0.75      0.76      1523\n",
      "weighted avg       0.78      0.77      0.77      1523\n",
      "\n",
      "Accuracy: 0.7728168089297439\n"
     ]
    }
   ],
   "source": [
    "bst = XGBClassifier()\n",
    "bst.fit(X_train_tfidf, df_train[\"target\"])\n",
    "preds = bst.predict(X_test_tfidf)\n",
    "\n",
    "print(classification_report(df_test[\"target\"], preds))\n",
    "print(\"Accuracy:\", accuracy_score(df_test[\"target\"], preds))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp-getting-started-fL89s8on",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
